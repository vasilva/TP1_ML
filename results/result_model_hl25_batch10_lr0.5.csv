hidden_layer,batch_size,learning_rate,taxa_acerto,num_epochs,training_loss,validation_loss
25,10,0.5,0.9098571428571428,36,"[2.163321446657181, 1.8659928538799286, 1.797901453256607, 1.7433029704093934, 1.724582099199295, 1.7117521533966065, 1.6703270745277405, 1.6094402813911437, 1.5752299304008484, 1.5598712866306306, 1.5492892506122589, 1.5415166478157043, 1.5360231351852418, 1.5308483440876006, 1.5264181616306305, 1.5220702855587005, 1.5194481813907623, 1.5157899873256684, 1.5129462711811066, 1.5112822229862213, 1.5089509785175323, 1.5069196467399597, 1.5048092486858369, 1.5031159727573395, 1.5019552886486054, 1.5001888127326966, 1.4991121244430543, 1.4982315385341645, 1.497228714466095, 1.4964632515907288, 1.4952456007003785, 1.49418447804451, 1.4936015186309815, 1.4926665563583374, 1.4922188556194305, 1.4914094738960266]","[1.970698160784585, 1.8208910964784168, 1.7585495171092806, 1.738316005184537, 1.7264420134680611, 1.705878354254223, 1.6770378038996743, 1.608239857923417, 1.5961108690216428, 1.584820656549363, 1.5800832708676655, 1.574514042763483, 1.5727769108045668, 1.5732490704173134, 1.5738983409745353, 1.5680420398712158, 1.5656412925039018, 1.564276056630271, 1.564827677749452, 1.565686305363973, 1.5633735798654103, 1.5609731106531053, 1.561209397656577, 1.5603156288464863, 1.5603049425851732, 1.5605299416042508, 1.5638389729318165, 1.5601682180450076, 1.5613328360375904, 1.5595271331923348, 1.5597475142706008, 1.562342575618199, 1.5580207819030398, 1.5585758629299344, 1.5586527245385307, 1.5581515090806144]"
