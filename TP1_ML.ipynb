{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7x8M1Q2U8Ow5"},"outputs":[],"source":["import torch\n","import csv\n","import numpy as np\n","import pandas as pd\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnX3nKDu8Ow9"},"outputs":[],"source":["class DigitDataset(Dataset):\n","    \"\"\"\n","    Classe para criar um Dataset a partir do arquivo de entrada\n","    \"\"\"\n","\n","    def __init__(self, path):\n","        \"\"\"\n","        Lê o arquivo de entrada e criar um array numpy\n","\n","        Args:\n","            path: Nome do arquivo de entrada\n","        \"\"\"\n","        self.data = pd.read_csv(path).values.astype(np.float32)\n","\n","    def __len__(self):\n","        \"\"\"\n","        Retorna o número de entradas\n","        \"\"\"\n","        return self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Retorna os valores x e y a partir do índice\n","\n","        Args:\n","            index: índice de entrada\n","        \"\"\"\n","        # Formato dos dados: [y[i], x[i,1], x[i,2], ..., x[i,784]]\n","        data = self.data[index, :]\n","        x = torch.from_numpy(data[1:]) / 255.0  # Normalizado para valores entre 0 e 1\n","        y = torch.from_numpy(np.array(data[0]).astype(int))\n","        return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RljhsLg-8Ow-"},"outputs":[],"source":["class MLP(nn.Module):\n","    \"\"\"\n","    Classe que cria um Multilayer Perceptron\n","    contendo 3 camadas\n","    1a: Entrada de tamanho 784 valores\n","    2a: Camada oculta de 25, 50 ou 100 nós\n","    3a: Saída com 10 valores\n","    Função de ativação Sigmoid\n","    Saída em Softmax\n","    \"\"\"\n","\n","    def __init__(self, input_size=784, hidden_layer=25, output_size=10):\n","        \"\"\"\n","        Cria as camadas do MLP\n","\n","        Args:\n","            input_size: Número de dimensões da entrada\n","            hidden_layer: Número de nurônios da camada oculta\n","            output_size: Número de classes da saída\n","        \"\"\"\n","        super(MLP, self).__init__()\n","        # Camada de Entrada\n","        self.fc1 = nn.Linear(input_size, hidden_layer)\n","        # Camada Oculta\n","        self.fc2 = nn.Linear(hidden_layer, output_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward Pass\n","\n","        Args:\n","            x: Entrada para a rede neural\n","        \"\"\"\n","        # Função de ativação Sigmoid\n","        x = F.sigmoid(self.fc1(x))\n","        # Saída por Softmax\n","        return F.softmax(self.fc2(x), dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFcyvXvm8Ow_"},"outputs":[],"source":["class EarlyStopping:\n","    \"\"\"\n","    Classe para determinar as condições de parada\n","    \"\"\"\n","\n","    def __init__(self, tolerance=4, min_delta=0.0):\n","        \"\"\"\n","        Args:\n","            tolerance: Número de epochs sem melhorar a loss\n","            min_delta: Valor mínimo da loss para parar\n","        \"\"\"\n","        self.tolerance = tolerance\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.min_validation_loss = np.inf\n","\n","    def __call__(self, validation_loss):\n","        \"\"\"\n","        Verifica se houve melhoria da loss\n","\n","        Args:\n","            validation_loss: Loss da validação\n","        \"\"\"\n","        # Não houve melhoria do valor da loss maior que min_delta\n","        if (validation_loss + self.min_delta) < self.min_validation_loss:\n","            self.min_validation_loss = validation_loss\n","            self.counter = 0\n","        # Houve melhoria do valor da loss maior que min_delta\n","        elif (validation_loss + self.min_delta) >= self.min_validation_loss:\n","            self.counter += 1\n","            if self.counter >= self.tolerance:\n","                return True\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qC-QiVk4CDnV"},"outputs":[],"source":["def train_one_epoch(model, train_dataloader, loss_func, optimiser, verbose=True):\n","    \"\"\"\n","    Função para treinar um epoch\n","\n","    Args:\n","        model: Modelo a ser treinado\n","        train_dataloader: DataLoader para o treinamento\n","        loss_func: Função de perda\n","        optimiser: Otimizador\n","        verbose: Verbose do treinamento\n","    \"\"\"\n","    # Colocar o modelo em modo de treinamento\n","    model.train()\n","    epoch_loss = 0.0\n","    for x, y in train_dataloader:\n","        # zerar os gradientes\n","        optimiser.zero_grad()\n","        # forward pass\n","        y_pred = model(x)\n","        # calcular a loss\n","        loss = loss_func(y_pred, y)\n","        # backward pass\n","        loss.backward()\n","        # atualizar os pesos\n","        optimiser.step()\n","        # somar a loss\n","        epoch_loss += loss.item()\n","\n","    epoch_loss /= len(train_dataloader)\n","    if verbose:\n","        print(f\"Training loss: {epoch_loss}\")\n","    return epoch_loss\n","\n","\n","def validate_one_epoch(model, validate_dataloader, loss_func, verbose=True):\n","    \"\"\"\n","    Função para validar um epoch\n","\n","    Args:\n","        model: Modelo a ser validado\n","        validate_dataloader: DataLoader para a validação\n","        loss_func: Função de perda\n","        verbose: Verbose do treinamento\n","    \"\"\"\n","    # Colocar o modelo em modo de avaliação\n","    model.eval()\n","    epoch_loss = 0.0\n","    y_eval = []\n","    with torch.no_grad():\n","        for x, y in validate_dataloader:\n","            # forward pass\n","            y_pred = model(x)\n","            # calcular a loss\n","            loss = loss_func(y_pred, y)\n","            # somar a loss\n","            epoch_loss += loss.item()\n","            # adicionar as predições\n","            y_eval.append(y_pred)\n","        epoch_loss /= len(validate_dataloader)\n","        if verbose:\n","            print(f\"Validation loss: {epoch_loss}\")\n","    return epoch_loss, y_eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_CHBJWRk8Ow_"},"outputs":[],"source":["def train_and_validate(\n","    max_epochs=1000,\n","    batch_size=10,\n","    hidden_layer=25,\n","    lr=0.5,\n","    tolerance=3,\n","    min_delta=0.01,\n","    verbose=True,\n","):\n","    \"\"\"\n","    Função principal do treinamento e validação\n","\n","    Args:\n","        max_epochs: Número máximo de epochs\n","        batch_size: Tamanho do batch\n","        hidden_layer: Número de nurônios da camada oculta\n","        lr: Taxa de aprendizado\n","        tolerance: Número de epochs sem melhorar a loss\n","        min_delta: Valor mínimo da loss para parar\n","        verbose: Verbose do treinamento\n","    \"\"\"\n","    print(\"-------------------------------\")\n","    print(\n","        \"Modelo: Hidden Layer %3d | Batch Size %4d | LR %2.1f\"\n","        % (hidden_layer, batch_size, lr)\n","    )\n","\n","    # Cria os datasets\n","    train_dataset = DigitDataset(\"data_tp1\")\n","    test_dataset = DigitDataset(\"validation.csv\")\n","    # Cria os dataloaders\n","    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n","    validate_dataloader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n","    # Cria o modelo\n","    model = MLP(hidden_layer=hidden_layer)\n","    loss_func = nn.CrossEntropyLoss()\n","    optimiser = optim.SGD(model.parameters(), lr=lr)\n","    train_loss = []\n","    validation_loss = []\n","    early_stopping = EarlyStopping(tolerance, min_delta)\n","\n","    for i in range(max_epochs):\n","        # treinamento\n","        if verbose:\n","            print(\"-------------------------------\")\n","            print(f\"Epoch {i+1}\")\n","        epoch_train_loss = train_one_epoch(\n","            model, train_dataloader, loss_func, optimiser, verbose\n","        )\n","        train_loss.append(epoch_train_loss)\n","\n","        # validação\n","        with torch.no_grad():\n","            epoch_validate_loss, y_eval = validate_one_epoch(\n","                model, validate_dataloader, loss_func, verbose\n","            )\n","            validation_loss.append(epoch_validate_loss)\n","\n","        # critério de parada\n","        if verbose and (i > 0):\n","            print(f\"Loss delta: {validation_loss[i-1] - validation_loss[i]}\")\n","        if early_stopping(epoch_validate_loss):\n","            print(f\"End at epoch: {i+1}\")\n","            break\n","\n","    num_epochs = i + 1\n","    output = np.array(y_eval).reshape(len(test_dataset), 10).argmax(axis=1)\n","    return train_loss, validation_loss, output, num_epochs, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sF98lG3QrhE3"},"outputs":[],"source":["def main(oculta=25, batch_size=10, lr=0.5, train_all_models=False):\n","    \"\"\"\n","    Treinamento e validação dos modelos\n","    Geração do arquivo csv com os resultados na pasta results\n","    Gravação dos modelos em disco na pasta models\n","\n","    Args:\n","        oculta: Número de nurônios da camada oculta\n","        batch_size: Tamanho do batch\n","        lr: Taxa de aprendizado\n","        train_all_models: Treinar todos os modelos\n","\n","    Atenção:\n","        Caso train_all_models seja True, fará o treinamento de todas\n","        as combinações de hiper-parâmetros, totalizando 84 treinamentos.\n","        Isso vai demorar literalmente algumas horas.\n","    \"\"\"\n","    # Criando um arquivo csv com os resultados\n","    if train_all_models:\n","        result = \"./results/results_all_models.csv\"\n","    else:\n","        result = f\"./results/result_model_hl{oculta}_batch{batch_size}_lr{lr}.csv\"\n","    with open(result, \"w\") as f:\n","        # Lendo os dados\n","        y_real = pd.read_csv(\"validation.csv\")[\"label\"].values.astype(np.int8)\n","        fieldnames = [\n","            \"hidden_layer\",\n","            \"batch_size\",\n","            \"learning_rate\",\n","            \"taxa_acerto\",\n","            \"num_epochs\",\n","            \"training_loss\",\n","            \"validation_loss\",\n","        ]\n","        writer = csv.DictWriter(f, fieldnames, lineterminator=\"\\n\")\n","        writer.writeheader()\n","\n","        # Hiper-parâmetros\n","        if train_all_models:\n","            camadas_ocultas = [25, 50, 100]\n","            batch_sizes = [1, 10, 50, 100, 500, 1000, 5000]\n","            learning_rates = [0.1, 0.5, 1.0, 10.0]\n","        else:\n","            camadas_ocultas = [oculta]\n","            batch_sizes = [batch_size]\n","            learning_rates = [lr]\n","\n","        # Todas as combinações de hiper-parâmetros\n","        for hl in camadas_ocultas:\n","            for batch in batch_sizes:\n","                for lr in learning_rates:\n","                    # Treinamento e validação\n","                    stats = [hl, batch, lr]\n","                    params = {\n","                        \"batch_size\": batch,\n","                        \"hidden_layer\": hl,\n","                        \"lr\": lr,\n","                        \"min_delta\": 0.0,\n","                    }\n","                    train_loss, validation_loss, y_pred, num_epochs, model = (\n","                        train_and_validate(**params)\n","                    )\n","                    torch.save(model, f\"./models/model_hl{hl}_batch{batch}_lr{lr}.pt\")\n","                    # Comparação\n","                    num_acertos = (y_real == y_pred).sum()\n","                    total = len(y_real)\n","                    taxa_acerto = num_acertos / total\n","                    # Escrevendo os resultados\n","                    stats += [taxa_acerto, num_epochs, train_loss, validation_loss]\n","                    writer.writerow(dict(zip(fieldnames, stats)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52403,"status":"ok","timestamp":1717180371187,"user":{"displayName":"Vinícius Alexandre","userId":"02678239040136017208"},"user_tz":180},"id":"qAKfqv3N4pZs","outputId":"a5e588bb-dbcb-4f00-f521-3529adf01568"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   10 | LR 0.5\n","-------------------------------\n","Epoch 1\n","Training loss: 2.163321446657181\n","Validation loss: 1.970698160784585\n","-------------------------------\n","Epoch 2\n","Training loss: 1.8659928538799286\n","Validation loss: 1.8208910964784168\n","Loss delta: 0.1498070643061682\n","-------------------------------\n","Epoch 3\n","Training loss: 1.797901453256607\n","Validation loss: 1.7585495171092806\n","Loss delta: 0.0623415793691362\n","-------------------------------\n","Epoch 4\n","Training loss: 1.7433029704093934\n","Validation loss: 1.738316005184537\n","Loss delta: 0.020233511924743652\n","-------------------------------\n","Epoch 5\n","Training loss: 1.724582099199295\n","Validation loss: 1.7264420134680611\n","Loss delta: 0.011873991716475851\n","-------------------------------\n","Epoch 6\n","Training loss: 1.7117521533966065\n","Validation loss: 1.705878354254223\n","Loss delta: 0.02056365921383807\n","-------------------------------\n","Epoch 7\n","Training loss: 1.6703270745277405\n","Validation loss: 1.6770378038996743\n","Loss delta: 0.0288405503545488\n","-------------------------------\n","Epoch 8\n","Training loss: 1.6094402813911437\n","Validation loss: 1.608239857923417\n","Loss delta: 0.06879794597625732\n","-------------------------------\n","Epoch 9\n","Training loss: 1.5752299304008484\n","Validation loss: 1.5961108690216428\n","Loss delta: 0.012128988901774163\n","-------------------------------\n","Epoch 10\n","Training loss: 1.5598712866306306\n","Validation loss: 1.584820656549363\n","Loss delta: 0.011290212472279793\n","-------------------------------\n","Epoch 11\n","Training loss: 1.5492892506122589\n","Validation loss: 1.5800832708676655\n","Loss delta: 0.004737385681697459\n","-------------------------------\n","Epoch 12\n","Training loss: 1.5415166478157043\n","Validation loss: 1.574514042763483\n","Loss delta: 0.005569228104182589\n","-------------------------------\n","Epoch 13\n","Training loss: 1.5360231351852418\n","Validation loss: 1.5727769108045668\n","Loss delta: 0.001737131958916116\n","-------------------------------\n","Epoch 14\n","Training loss: 1.5308483440876006\n","Validation loss: 1.5732490704173134\n","Loss delta: -0.00047215961274660323\n","-------------------------------\n","Epoch 15\n","Training loss: 1.5264181616306305\n","Validation loss: 1.5738983409745353\n","Loss delta: -0.0006492705572218593\n","-------------------------------\n","Epoch 16\n","Training loss: 1.5220702855587005\n","Validation loss: 1.5680420398712158\n","Loss delta: 0.005856301103319472\n","-------------------------------\n","Epoch 17\n","Training loss: 1.5194481813907623\n","Validation loss: 1.5656412925039018\n","Loss delta: 0.0024007473673139934\n","-------------------------------\n","Epoch 18\n","Training loss: 1.5157899873256684\n","Validation loss: 1.564276056630271\n","Loss delta: 0.00136523587363091\n","-------------------------------\n","Epoch 19\n","Training loss: 1.5129462711811066\n","Validation loss: 1.564827677749452\n","Loss delta: -0.0005516211191811671\n","-------------------------------\n","Epoch 20\n","Training loss: 1.5112822229862213\n","Validation loss: 1.565686305363973\n","Loss delta: -0.0008586276145208238\n","-------------------------------\n","Epoch 21\n","Training loss: 1.5089509785175323\n","Validation loss: 1.5633735798654103\n","Loss delta: 0.002312725498562651\n","-------------------------------\n","Epoch 22\n","Training loss: 1.5069196467399597\n","Validation loss: 1.5609731106531053\n","Loss delta: 0.0024004692123049676\n","-------------------------------\n","Epoch 23\n","Training loss: 1.5048092486858369\n","Validation loss: 1.561209397656577\n","Loss delta: -0.0002362870034717801\n","-------------------------------\n","Epoch 24\n","Training loss: 1.5031159727573395\n","Validation loss: 1.5603156288464863\n","Loss delta: 0.0008937688100907337\n","-------------------------------\n","Epoch 25\n","Training loss: 1.5019552886486054\n","Validation loss: 1.5603049425851732\n","Loss delta: 1.0686261313175294e-05\n","-------------------------------\n","Epoch 26\n","Training loss: 1.5001888127326966\n","Validation loss: 1.5605299416042508\n","Loss delta: -0.00022499901907768738\n","-------------------------------\n","Epoch 27\n","Training loss: 1.4991121244430543\n","Validation loss: 1.5638389729318165\n","Loss delta: -0.003309031327565659\n","-------------------------------\n","Epoch 28\n","Training loss: 1.4982315385341645\n","Validation loss: 1.5601682180450076\n","Loss delta: 0.0036707548868089024\n","-------------------------------\n","Epoch 29\n","Training loss: 1.497228714466095\n","Validation loss: 1.5613328360375904\n","Loss delta: -0.0011646179925828282\n","-------------------------------\n","Epoch 30\n","Training loss: 1.4964632515907288\n","Validation loss: 1.5595271331923348\n","Loss delta: 0.0018057028452556079\n","-------------------------------\n","Epoch 31\n","Training loss: 1.4952456007003785\n","Validation loss: 1.5597475142706008\n","Loss delta: -0.000220381078265941\n","-------------------------------\n","Epoch 32\n","Training loss: 1.49418447804451\n","Validation loss: 1.562342575618199\n","Loss delta: -0.0025950613475982376\n","-------------------------------\n","Epoch 33\n","Training loss: 1.4936015186309815\n","Validation loss: 1.5580207819030398\n","Loss delta: 0.004321793715159172\n","-------------------------------\n","Epoch 34\n","Training loss: 1.4926665563583374\n","Validation loss: 1.5585758629299344\n","Loss delta: -0.0005550810268946105\n","-------------------------------\n","Epoch 35\n","Training loss: 1.4922188556194305\n","Validation loss: 1.5586527245385307\n","Loss delta: -7.68616085962126e-05\n","-------------------------------\n","Epoch 36\n","Training loss: 1.4914094738960266\n","Validation loss: 1.5581515090806144\n","Loss delta: 0.0005012154579162598\n","End at epoch: 36\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6s3arpBROnTb"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
