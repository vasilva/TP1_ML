{"cells":[{"cell_type":"code","execution_count":40,"metadata":{"id":"7x8M1Q2U8Ow5"},"outputs":[],"source":["import torch\n","import csv\n","import numpy as np\n","import pandas as pd\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"cnX3nKDu8Ow9"},"outputs":[],"source":["class DigitDataset(Dataset):\n","    \"\"\"\n","    Classe para criar um Dataset a partir do arquivo de entrada\n","    \"\"\"\n","\n","    def __init__(self, path):\n","        \"\"\"\n","        Lê o arquivo de entrada e criar um array numpy\n","\n","        Args:\n","            path: Nome do arquivo de entrada\n","        \"\"\"\n","        self.data = pd.read_csv(path).values.astype(np.float32)\n","\n","    def __len__(self):\n","        \"\"\"\n","        Retorna o número de entradas\n","        \"\"\"\n","        return self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Retorna os valores x e y a partir do índice\n","\n","        Args:\n","            index: índice de entrada\n","        \"\"\"\n","        # Formato dos dados: [y[i], x[i,1], x[i,2], ..., x[i,784]]\n","        data = self.data[index, :]\n","        x = torch.from_numpy(data[1:]) / 255.0  # Normalizado para valores entre 0 e 1\n","        y = torch.from_numpy(np.array(data[0]).astype(int))\n","        return x, y"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"RljhsLg-8Ow-"},"outputs":[],"source":["class MLP(nn.Module):\n","    \"\"\"\n","    Classe que cria um Multilayer Perceptron\n","    contendo 3 camadas\n","    1a: Entrada de tamanho 784 valores\n","    2a: Camada oculta de 25, 50 ou 100 nós\n","    3a: Saída com 10 valores\n","    Função de ativação Sigmoid\n","    Saída em Softmax\n","    \"\"\"\n","\n","    def __init__(self, input_size=784, hidden_layer=25, output_size=10):\n","        \"\"\"\n","        Cria as camadas do MLP\n","\n","        Args:\n","            input_size: Número de dimensões da entrada\n","            hidden_layer: Número de nurônios da camada oculta\n","            output_size: Número de classes da saída\n","        \"\"\"\n","        super(MLP, self).__init__()\n","        # Camada de Entrada\n","        self.fc1 = nn.Linear(input_size, hidden_layer)\n","        # Camada Oculta\n","        self.fc2 = nn.Linear(hidden_layer, output_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward Pass\n","\n","        Args:\n","            x: Entrada para a rede neural\n","        \"\"\"\n","        # Função de ativação Sigmoid\n","        x = F.sigmoid(self.fc1(x))\n","        # Saída por Softmax\n","        return F.softmax(self.fc2(x), dim=1)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"gFcyvXvm8Ow_"},"outputs":[],"source":["class EarlyStopping:\n","    \"\"\"\n","    Classe para determinar as condições de parada\n","    \"\"\"\n","\n","    def __init__(self, tolerance=4, min_delta=0.0):\n","        \"\"\"\n","        Args:\n","            tolerance: Número de epochs sem melhorar a loss\n","            min_delta: Valor mínimo da loss para parar\n","        \"\"\"\n","        self.tolerance = tolerance\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.min_validation_loss = np.inf\n","\n","    def __call__(self, validation_loss):\n","        \"\"\"\n","        Verifica se houve melhoria da loss\n","\n","        Args:\n","            validation_loss: Loss da validação\n","        \"\"\"\n","        # Não houve melhoria do valor da loss maior que min_delta\n","        if (validation_loss + self.min_delta) < self.min_validation_loss:\n","            self.min_validation_loss = validation_loss\n","            self.counter = 0\n","        # Houve melhoria do valor da loss maior que min_delta\n","        elif (validation_loss + self.min_delta) >= self.min_validation_loss:\n","            self.counter += 1\n","            if self.counter >= self.tolerance:\n","                return True\n","        return False"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"qC-QiVk4CDnV"},"outputs":[],"source":["def train_one_epoch(model, train_dataloader, loss_func, optimiser, verbose=True):\n","    \"\"\"\n","    Função para treinar um epoch\n","\n","    Args:\n","        model: Modelo a ser treinado\n","        train_dataloader: DataLoader para o treinamento\n","        loss_func: Função de perda\n","        optimiser: Otimizador\n","        verbose: Verbose do treinamento\n","    \"\"\"\n","    # Colocar o modelo em modo de treinamento\n","    model.train()\n","    epoch_loss = 0.0\n","    for x, y in train_dataloader:\n","        # zerar os gradientes\n","        optimiser.zero_grad()\n","        # forward pass\n","        y_pred = model(x)\n","        # calcular a loss\n","        loss = loss_func(y_pred, y)\n","        # backward pass\n","        loss.backward()\n","        # atualizar os pesos\n","        optimiser.step()\n","        # somar a loss\n","        epoch_loss += loss.item()\n","\n","    epoch_loss /= len(train_dataloader)\n","    if verbose:\n","        print(f\"Training loss: {epoch_loss}\")\n","    return epoch_loss\n","\n","\n","def validate_one_epoch(model, validate_dataloader, loss_func, verbose=True):\n","    \"\"\"\n","    Função para validar um epoch\n","\n","    Args:\n","        model: Modelo a ser validado\n","        validate_dataloader: DataLoader para a validação\n","        loss_func: Função de perda\n","        verbose: Verbose do treinamento\n","    \"\"\"\n","    # Colocar o modelo em modo de avaliação\n","    model.eval()\n","    epoch_loss = 0.0\n","    y_eval = []\n","    with torch.no_grad():\n","        for x, y in validate_dataloader:\n","            # forward pass\n","            y_pred = model(x)\n","            # calcular a loss\n","            loss = loss_func(y_pred, y)\n","            # somar a loss\n","            epoch_loss += loss.item()\n","            # adicionar as predições\n","            y_eval.append(y_pred)\n","        epoch_loss /= len(validate_dataloader)\n","        if verbose:\n","            print(f\"Validation loss: {epoch_loss}\")\n","    return epoch_loss, y_eval"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"_CHBJWRk8Ow_"},"outputs":[],"source":["def train_and_validate(\n","    max_epochs=1000,\n","    batch_size=10,\n","    hidden_layer=25,\n","    lr=0.5,\n","    tolerance=3,\n","    min_delta=0.01,\n","    verbose=True,\n","):\n","    \"\"\"\n","    Função principal do treinamento e validação\n","\n","    Args:\n","        max_epochs: Número máximo de epochs\n","        batch_size: Tamanho do batch\n","        hidden_layer: Número de nurônios da camada oculta\n","        lr: Taxa de aprendizado\n","        tolerance: Número de epochs sem melhorar a loss\n","        min_delta: Valor mínimo da loss para parar\n","        verbose: Verbose do treinamento\n","    \"\"\"\n","    print(\"-------------------------------\")\n","    print(\n","        \"Modelo: Hidden Layer %3d | Batch Size %4d | LR %2.1f\"\n","        % (hidden_layer, batch_size, lr)\n","    )\n","\n","    # Cria os datasets\n","    train_dataset = DigitDataset(\"data_tp1\")\n","    test_dataset = DigitDataset(\"validation.csv\")\n","    # Cria os dataloaders\n","    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n","    validate_dataloader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n","    # Cria o modelo\n","    model = MLP(hidden_layer=hidden_layer)\n","    loss_func = nn.CrossEntropyLoss()\n","    optimiser = optim.SGD(model.parameters(), lr=lr)\n","    train_loss = []\n","    validation_loss = []\n","    early_stopping = EarlyStopping(tolerance, min_delta)\n","\n","    for i in range(max_epochs):\n","        # treinamento\n","        if verbose:\n","            print(\"-------------------------------\")\n","            print(f\"Epoch {i+1}\")\n","        epoch_train_loss = train_one_epoch(\n","            model, train_dataloader, loss_func, optimiser, verbose\n","        )\n","        train_loss.append(epoch_train_loss)\n","\n","        # validação\n","        with torch.no_grad():\n","            epoch_validate_loss, y_eval = validate_one_epoch(\n","                model, validate_dataloader, loss_func, verbose\n","            )\n","            validation_loss.append(epoch_validate_loss)\n","\n","        # critério de parada\n","        if verbose and (i > 0):\n","            print(f\"Loss delta: {validation_loss[i-1] - validation_loss[i]}\")\n","        if early_stopping(epoch_validate_loss):\n","            print(\"-------------------------------\")\n","            print(f\"End at epoch: {i+1}\")\n","            print(\"===============================\")\n","            break\n","\n","    num_epochs = i + 1\n","    output = np.array(y_eval).reshape(len(test_dataset), 10).argmax(axis=1)\n","    torch.save(model, f\"./models/model_hl{hidden_layer}_batch{batch_size}_lr{lr}.pt\")\n","    return train_loss, validation_loss, output, num_epochs"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"sF98lG3QrhE3"},"outputs":[],"source":["def main(oculta=25, batch_size=10, lr=0.5, train_all_models=False, verbose=True):\n","    \"\"\"\n","    Treinamento e validação dos modelos\n","    Geração do arquivo csv com os resultados na pasta results\n","    Gravação dos modelos em disco na pasta models\n","\n","    Args:\n","        oculta: Número de nurônios da camada oculta\n","        batch_size: Tamanho do batch\n","        lr: Taxa de aprendizado\n","        train_all_models: Treinar todos os modelos\n","\n","    Atenção:\n","        Caso train_all_models seja True, fará o treinamento de todas\n","        as combinações de hiper-parâmetros, totalizando 84 treinamentos.\n","        Isso vai demorar literalmente algumas horas.\n","    \"\"\"\n","    # Criando um arquivo csv com os resultados\n","    if train_all_models:\n","        result = \"./results/results_all_models.csv\"\n","    else:\n","        result = f\"./results/result_model_hl{oculta}_batch{batch_size}_lr{lr}.csv\"\n","    with open(result, \"w\") as f:\n","        # Lendo os dados\n","        y_real = pd.read_csv(\"validation.csv\")[\"label\"].values.astype(np.int8)\n","        fieldnames = [\n","            \"hidden_layer\",\n","            \"batch_size\",\n","            \"learning_rate\",\n","            \"taxa_acerto\",\n","            \"num_epochs\",\n","            \"training_loss\",\n","            \"validation_loss\",\n","        ]\n","        writer = csv.DictWriter(f, fieldnames, lineterminator=\"\\n\")\n","        writer.writeheader()\n","\n","        # Hiper-parâmetros\n","        if train_all_models:\n","            camadas_ocultas = [25, 50, 100]\n","            batch_sizes = [1, 10, 50, 100, 500, 1000, 5000]\n","            learning_rates = [0.1, 0.5, 1.0, 10.0]\n","        else:\n","            camadas_ocultas = [oculta]\n","            batch_sizes = [batch_size]\n","            learning_rates = [lr]\n","\n","        i = 1\n","        n = len(camadas_ocultas) * len(batch_sizes) * len(learning_rates)\n","        # Todas as combinações de hiper-parâmetros\n","        for hl in camadas_ocultas:\n","            for batch in batch_sizes:\n","                for lr in learning_rates:\n","                    # Treinamento e validação\n","                    print(f\"Treinamento de modelo {i}/{n}\")\n","                    stats = [hl, batch, lr]\n","                    params = {\n","                        \"batch_size\": batch,\n","                        \"hidden_layer\": hl,\n","                        \"lr\": lr,\n","                        \"min_delta\": 0.0,\n","                        \"tolerance\": 4,\n","                        \"verbose\": verbose,\n","                    }\n","                    train_loss, validation_loss, y_pred, num_epochs = (\n","                        train_and_validate(**params)\n","                    )\n","\n","                    # Comparação\n","                    num_acertos = (y_real == y_pred).sum()\n","                    total = len(y_real)\n","                    taxa_acerto = num_acertos / total\n","                    # Escrevendo os resultados\n","                    stats += [taxa_acerto, num_epochs, train_loss, validation_loss]\n","                    writer.writerow(dict(zip(fieldnames, stats)))\n","                    i += 1\n","        f.close()"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52403,"status":"ok","timestamp":1717180371187,"user":{"displayName":"Vinícius Alexandre","userId":"02678239040136017208"},"user_tz":180},"id":"qAKfqv3N4pZs","outputId":"a5e588bb-dbcb-4f00-f521-3529adf01568"},"outputs":[{"name":"stdout","output_type":"stream","text":["Treinamento de modelo 1/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size    1 | LR 0.1\n","-------------------------------\n","End at epoch: 23\n","===============================\n","Treinamento de modelo 2/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size    1 | LR 0.5\n","-------------------------------\n","End at epoch: 14\n","===============================\n","Treinamento de modelo 3/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size    1 | LR 1.0\n","-------------------------------\n","End at epoch: 15\n","===============================\n","Treinamento de modelo 4/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size    1 | LR 10.0\n","-------------------------------\n","End at epoch: 5\n","===============================\n","Treinamento de modelo 5/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   10 | LR 0.1\n","-------------------------------\n","End at epoch: 135\n","===============================\n","Treinamento de modelo 6/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   10 | LR 0.5\n","-------------------------------\n","End at epoch: 43\n","===============================\n","Treinamento de modelo 7/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   10 | LR 1.0\n","-------------------------------\n","End at epoch: 28\n","===============================\n","Treinamento de modelo 8/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   10 | LR 10.0\n","-------------------------------\n","End at epoch: 11\n","===============================\n","Treinamento de modelo 9/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   50 | LR 0.1\n","-------------------------------\n","End at epoch: 340\n","===============================\n","Treinamento de modelo 10/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   50 | LR 0.5\n","-------------------------------\n","End at epoch: 123\n","===============================\n","Treinamento de modelo 11/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   50 | LR 1.0\n","-------------------------------\n","End at epoch: 60\n","===============================\n","Treinamento de modelo 12/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size   50 | LR 10.0\n","-------------------------------\n","End at epoch: 16\n","===============================\n","Treinamento de modelo 13/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  100 | LR 0.1\n","-------------------------------\n","End at epoch: 613\n","===============================\n","Treinamento de modelo 14/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  100 | LR 0.5\n","-------------------------------\n","End at epoch: 143\n","===============================\n","Treinamento de modelo 15/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  100 | LR 1.0\n","-------------------------------\n","End at epoch: 123\n","===============================\n","Treinamento de modelo 16/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  100 | LR 10.0\n","-------------------------------\n","End at epoch: 58\n","===============================\n","Treinamento de modelo 17/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  500 | LR 0.1\n","Treinamento de modelo 18/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  500 | LR 0.5\n","-------------------------------\n","End at epoch: 619\n","===============================\n","Treinamento de modelo 19/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  500 | LR 1.0\n","-------------------------------\n","End at epoch: 305\n","===============================\n","Treinamento de modelo 20/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size  500 | LR 10.0\n","-------------------------------\n","End at epoch: 35\n","===============================\n","Treinamento de modelo 21/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 1000 | LR 0.1\n","Treinamento de modelo 22/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 1000 | LR 0.5\n","Treinamento de modelo 23/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 1000 | LR 1.0\n","-------------------------------\n","End at epoch: 487\n","===============================\n","Treinamento de modelo 24/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 1000 | LR 10.0\n","-------------------------------\n","End at epoch: 53\n","===============================\n","Treinamento de modelo 25/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 5000 | LR 0.1\n","Treinamento de modelo 26/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 5000 | LR 0.5\n","Treinamento de modelo 27/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 5000 | LR 1.0\n","Treinamento de modelo 28/84\n","-------------------------------\n","Modelo: Hidden Layer  25 | Batch Size 5000 | LR 10.0\n","-------------------------------\n","End at epoch: 131\n","===============================\n","Treinamento de modelo 29/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size    1 | LR 0.1\n","-------------------------------\n","End at epoch: 31\n","===============================\n","Treinamento de modelo 30/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size    1 | LR 0.5\n","-------------------------------\n","End at epoch: 17\n","===============================\n","Treinamento de modelo 31/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size    1 | LR 1.0\n","-------------------------------\n","End at epoch: 27\n","===============================\n","Treinamento de modelo 32/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size    1 | LR 10.0\n","-------------------------------\n","End at epoch: 7\n","===============================\n","Treinamento de modelo 33/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   10 | LR 0.1\n","-------------------------------\n","End at epoch: 145\n","===============================\n","Treinamento de modelo 34/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   10 | LR 0.5\n","-------------------------------\n","End at epoch: 36\n","===============================\n","Treinamento de modelo 35/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   10 | LR 1.0\n","-------------------------------\n","End at epoch: 35\n","===============================\n","Treinamento de modelo 36/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   10 | LR 10.0\n","-------------------------------\n","End at epoch: 21\n","===============================\n","Treinamento de modelo 37/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   50 | LR 0.1\n","-------------------------------\n","End at epoch: 467\n","===============================\n","Treinamento de modelo 38/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   50 | LR 0.5\n","-------------------------------\n","End at epoch: 78\n","===============================\n","Treinamento de modelo 39/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   50 | LR 1.0\n","-------------------------------\n","End at epoch: 70\n","===============================\n","Treinamento de modelo 40/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size   50 | LR 10.0\n","-------------------------------\n","End at epoch: 66\n","===============================\n","Treinamento de modelo 41/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  100 | LR 0.1\n","-------------------------------\n","End at epoch: 432\n","===============================\n","Treinamento de modelo 42/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  100 | LR 0.5\n","-------------------------------\n","End at epoch: 137\n","===============================\n","Treinamento de modelo 43/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  100 | LR 1.0\n","-------------------------------\n","End at epoch: 86\n","===============================\n","Treinamento de modelo 44/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  100 | LR 10.0\n","-------------------------------\n","End at epoch: 24\n","===============================\n","Treinamento de modelo 45/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  500 | LR 0.1\n","Treinamento de modelo 46/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  500 | LR 0.5\n","-------------------------------\n","End at epoch: 594\n","===============================\n","Treinamento de modelo 47/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  500 | LR 1.0\n","-------------------------------\n","End at epoch: 222\n","===============================\n","Treinamento de modelo 48/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size  500 | LR 10.0\n","-------------------------------\n","End at epoch: 63\n","===============================\n","Treinamento de modelo 49/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 1000 | LR 0.1\n","Treinamento de modelo 50/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 1000 | LR 0.5\n","Treinamento de modelo 51/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 1000 | LR 1.0\n","-------------------------------\n","End at epoch: 497\n","===============================\n","Treinamento de modelo 52/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 1000 | LR 10.0\n","-------------------------------\n","End at epoch: 77\n","===============================\n","Treinamento de modelo 53/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 5000 | LR 0.1\n","Treinamento de modelo 54/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 5000 | LR 0.5\n","Treinamento de modelo 55/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 5000 | LR 1.0\n","Treinamento de modelo 56/84\n","-------------------------------\n","Modelo: Hidden Layer  50 | Batch Size 5000 | LR 10.0\n","Treinamento de modelo 57/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size    1 | LR 0.1\n","-------------------------------\n","End at epoch: 59\n","===============================\n","Treinamento de modelo 58/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size    1 | LR 0.5\n","-------------------------------\n","End at epoch: 39\n","===============================\n","Treinamento de modelo 59/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size    1 | LR 1.0\n","-------------------------------\n","End at epoch: 12\n","===============================\n","Treinamento de modelo 60/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size    1 | LR 10.0\n","-------------------------------\n","End at epoch: 5\n","===============================\n","Treinamento de modelo 61/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   10 | LR 0.1\n","-------------------------------\n","End at epoch: 131\n","===============================\n","Treinamento de modelo 62/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   10 | LR 0.5\n","-------------------------------\n","End at epoch: 45\n","===============================\n","Treinamento de modelo 63/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   10 | LR 1.0\n","-------------------------------\n","End at epoch: 34\n","===============================\n","Treinamento de modelo 64/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   10 | LR 10.0\n","-------------------------------\n","End at epoch: 28\n","===============================\n","Treinamento de modelo 65/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   50 | LR 0.1\n","-------------------------------\n","End at epoch: 300\n","===============================\n","Treinamento de modelo 66/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   50 | LR 0.5\n","-------------------------------\n","End at epoch: 113\n","===============================\n","Treinamento de modelo 67/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   50 | LR 1.0\n","-------------------------------\n","End at epoch: 29\n","===============================\n","Treinamento de modelo 68/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size   50 | LR 10.0\n","-------------------------------\n","End at epoch: 34\n","===============================\n","Treinamento de modelo 69/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  100 | LR 0.1\n","-------------------------------\n","End at epoch: 590\n","===============================\n","Treinamento de modelo 70/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  100 | LR 0.5\n","-------------------------------\n","End at epoch: 149\n","===============================\n","Treinamento de modelo 71/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  100 | LR 1.0\n","-------------------------------\n","End at epoch: 53\n","===============================\n","Treinamento de modelo 72/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  100 | LR 10.0\n","-------------------------------\n","End at epoch: 19\n","===============================\n","Treinamento de modelo 73/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  500 | LR 0.1\n","Treinamento de modelo 74/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  500 | LR 0.5\n","-------------------------------\n","End at epoch: 531\n","===============================\n","Treinamento de modelo 75/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  500 | LR 1.0\n","-------------------------------\n","End at epoch: 275\n","===============================\n","Treinamento de modelo 76/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size  500 | LR 10.0\n","-------------------------------\n","End at epoch: 45\n","===============================\n","Treinamento de modelo 77/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 1000 | LR 0.1\n","Treinamento de modelo 78/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 1000 | LR 0.5\n","Treinamento de modelo 79/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 1000 | LR 1.0\n","-------------------------------\n","End at epoch: 352\n","===============================\n","Treinamento de modelo 80/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 1000 | LR 10.0\n","-------------------------------\n","End at epoch: 64\n","===============================\n","Treinamento de modelo 81/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 5000 | LR 0.1\n","Treinamento de modelo 82/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 5000 | LR 0.5\n","Treinamento de modelo 83/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 5000 | LR 1.0\n","Treinamento de modelo 84/84\n","-------------------------------\n","Modelo: Hidden Layer 100 | Batch Size 5000 | LR 10.0\n","-------------------------------\n","End at epoch: 12\n","===============================\n"]}],"source":["if __name__ == \"__main__\":\n","    main(train_all_models=True, verbose=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
